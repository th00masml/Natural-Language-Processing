{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the English language class\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create the nlp object\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "look\n",
      "before\n",
      "and\n",
      "after\n",
      ",\n",
      "And\n",
      "pine\n",
      "for\n",
      "what\n",
      "is\n",
      "not\n",
      ";\n",
      "Our\n",
      "sincerest\n",
      "laughter\n",
      "With\n",
      "some\n",
      "pain\n",
      "is\n",
      "fraught\n",
      ";\n",
      "Our\n",
      "sweetest\n",
      "songs\n",
      "are\n",
      "those\n",
      "that\n",
      "tell\n",
      "Of\n",
      "saddest\n",
      "thought\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Created by processing a string of text with the nlp object\n",
    "doc = nlp(\"It really is a nice theory. The only defect I think it has is probably common to all philosophical theories. It's wrong.\")\n",
    "\n",
    "# Iterate over tokens in a Doc\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Span object is a slice of the document consisting of one or more tokens. \n",
    "\n",
    "It's only a view of the Doc and doesn't contain any data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "really is a\n"
     ]
    }
   ],
   "source": [
    "# A slice from the Doc is a Span object\n",
    "span = doc[1:4]\n",
    "\n",
    "# Get the span text via the .text attribute\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical Attributes\n",
    "\n",
    "\"i\" is the index of the token within the parent document.\n",
    "\n",
    "\"text\" returns the token text.\n",
    "\n",
    "\"is alpha\", \"is punct\" and \"like num\" return boolean values indicating whether the token consists of alphabetic characters, whether it's punctuation or whether it resembles a number. For example, a token \"10\" – one, zero – or the word \"ten\" – T, E, N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "Text:     ['It', 'really', 'is', 'a', 'nice', 'theory', '.', 'The', 'only', 'defect', 'I', 'think', 'it', 'has', 'is', 'probably', 'common', 'to', 'all', 'philosophical', 'theories', '.', 'It', \"'s\", 'wrong', '.']\n",
      "is_alpha: [True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False]\n",
      "is_punct: [False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True]\n",
      "like_num: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print('Index:   ', [token.i for token in doc])\n",
    "print('Text:    ', [token.text for token in doc])\n",
    "\n",
    "print('is_alpha:', [token.is_alpha for token in doc])\n",
    "print('is_punct:', [token.is_punct for token in doc])\n",
    "print('like_num:', [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
