{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.1',\n",
       " '2.1.0',\n",
       " '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras, tensorflow, sys\n",
    "keras.__version__, tensorflow.__version__, sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Dense, Input, Flatten, Lambda, Permute, GlobalMaxPooling1D, Activation, Concatenate\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Embedding, Dropout, Bidirectional, CuDNNGRU, SpatialDropout1D\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load intents from:\n",
    "\n",
    "https://github.com/snipsco/nlu-benchmark/tree/master/2017-06-custom-intent-engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13784, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with intents\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
    "               'SearchScreeningEvent']:\n",
    "\n",
    "    with open(\"2017-06-custom-intent-engines/\" + intent + \"/train_\" + intent + \"_full.json\",\n",
    "              encoding='cp1251') as data_file:\n",
    "        full_data = json.load(data_file)\n",
    "        \n",
    "    texts = []\n",
    "    for i in range(len(full_data[intent])):\n",
    "        text = ''\n",
    "        for j in range(len(full_data[intent][i]['data'])):\n",
    "            text += full_data[intent][i]['data'][j]['text']\n",
    "        texts.append(text)\n",
    "\n",
    "    dftrain = pd.DataFrame(data=texts, columns=['request'])\n",
    "    dftrain[intent] = np.ones(dftrain.shape[0], dtype='int')\n",
    "\n",
    "    data = data.append(dftrain, ignore_index=True, sort=False)\n",
    "\n",
    "data = data.fillna(value=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>AddToPlaylist</th>\n",
       "      <th>BookRestaurant</th>\n",
       "      <th>GetWeather</th>\n",
       "      <th>PlayMusic</th>\n",
       "      <th>RateBook</th>\n",
       "      <th>SearchCreativeWork</th>\n",
       "      <th>SearchScreeningEvent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Add another song to the Cita RomГЎntica playli...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add clem burke in my playlist Pre-Party R&amp;B Jams</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add Live from Aragon Ballroom to Trapeo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>add Unite and Win to my night out</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Add track to my Digster Future Hits</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>add the piano bar to my Cindy Wilson</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Add Spanish Harlem Incident to cleaning the house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>add The Greyest of Blue Skies in Indie EspaГ±o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Add the name kids in the street to the plylist...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>add album radar latino</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             request  AddToPlaylist  \\\n",
       "0  Add another song to the Cita RomГЎntica playli...            1.0   \n",
       "1   add clem burke in my playlist Pre-Party R&B Jams            1.0   \n",
       "2            Add Live from Aragon Ballroom to Trapeo            1.0   \n",
       "3                  add Unite and Win to my night out            1.0   \n",
       "4                Add track to my Digster Future Hits            1.0   \n",
       "5               add the piano bar to my Cindy Wilson            1.0   \n",
       "6  Add Spanish Harlem Incident to cleaning the house            1.0   \n",
       "7  add The Greyest of Blue Skies in Indie EspaГ±o...            1.0   \n",
       "8  Add the name kids in the street to the plylist...            1.0   \n",
       "9                             add album radar latino            1.0   \n",
       "\n",
       "   BookRestaurant  GetWeather  PlayMusic  RateBook  SearchCreativeWork  \\\n",
       "0             0.0         0.0        0.0       0.0                 0.0   \n",
       "1             0.0         0.0        0.0       0.0                 0.0   \n",
       "2             0.0         0.0        0.0       0.0                 0.0   \n",
       "3             0.0         0.0        0.0       0.0                 0.0   \n",
       "4             0.0         0.0        0.0       0.0                 0.0   \n",
       "5             0.0         0.0        0.0       0.0                 0.0   \n",
       "6             0.0         0.0        0.0       0.0                 0.0   \n",
       "7             0.0         0.0        0.0       0.0                 0.0   \n",
       "8             0.0         0.0        0.0       0.0                 0.0   \n",
       "9             0.0         0.0        0.0       0.0                 0.0   \n",
       "\n",
       "   SearchScreeningEvent  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "5                   0.0  \n",
       "6                   0.0  \n",
       "7                   0.0  \n",
       "8                   0.0  \n",
       "9                   0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained embeddings:\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = 'D:/NLP Files/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = len(word_index)\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"request\"], data[[\"AddToPlaylist\", \"BookRestaurant\",\n",
    "                                                    \"GetWeather\", \"PlayMusic\", \"RateBook\", \"SearchCreativeWork\",\n",
    "                                                    \"SearchScreeningEvent\"]], test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of the data: tokenizing and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3331: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "X_train = list(X_train)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Hardcoded parameters\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)\n",
    "max_sent_len = 100\n",
    "\n",
    "\n",
    "# Pad\n",
    "X_train = pad_sequences(X_train, maxlen=max_sent_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_sent_len)\n",
    "\n",
    "embedding_matrix = load_glove(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(np.array(y_train), axis=-1)\n",
    "y_test = np.argmax(np.array(y_test), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model with pretrained glove vectors as embedding weights.\n",
    "Using GRU (Gated Recurrent Unit) and Global Max Pooling 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=256, activation=\"tanh\", padding=\"same\", strides=1, kernel_size=3)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 100, 300)     2908500     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 100, 300)     0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 100, 256)     230656      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 100, 256)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100, 256)     0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 100, 1)       257         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 1, 100)       0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attn_softmax (Activation)       (None, 1, 100)       0           permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 256)       0           attn_softmax[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 256)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512)          0           global_max_pooling1d_4[0][0]     \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 512)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          65664       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 128)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           4128        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 7)            231         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,209,436\n",
      "Trainable params: 3,209,436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_sent_len,), dtype='int32')\n",
    "\n",
    "words = Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1], weights=[embedding_matrix],\n",
    "                  trainable=True)(sequence_input)\n",
    "words = Dropout(rate=0.3)(words)\n",
    "\n",
    "output = Convolution1D(filters=256, filter_length=3, activation=\"tanh\", padding='same', strides=1)(words)\n",
    "output = Dropout(rate=0.3)(output)\n",
    "\n",
    "# tf.contrib is not available in tf 2.0. Need to change it with something else\n",
    "#output = Bidirectional(CuDNNGRU(units=64, return_sequences=True), merge_mode='concat')(output)\n",
    "output_h = Activation('tanh')(output)\n",
    "\n",
    "output1 = GlobalMaxPooling1D()(output_h) \n",
    "\n",
    "# Applying attention to RNN output\n",
    "output = Dense(units=1)(output_h)\n",
    "output = Permute((2, 1))(output)\n",
    "output = Activation('softmax', name=\"attn_softmax\")(output)\n",
    "output = Lambda(lambda x: tf.matmul(x[0], x[1])) ([output, output_h])\n",
    "output2 = Flatten() (output)\n",
    "\n",
    "# Concatenating maxpooled and self attended features.\n",
    "output = Concatenate()([output1, output2])\n",
    "output = Dropout(rate=0.3)(output)\n",
    "\n",
    "output = Dense(units=128, activation='tanh')(output)\n",
    "output = Dropout(rate=0.3)(output)\n",
    "\n",
    "output = Dense(units=32, activation='tanh')(output)\n",
    "output = Dense(units=7, activation='softmax')(output)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10338/10338 [==============================] - 3s 291us/step - loss: 1.1443 - accuracy: 0.60600s - loss: 1.2115 - accuracy\n",
      "Epoch 2/10\n",
      "10338/10338 [==============================] - 2s 236us/step - loss: 0.2204 - accuracy: 0.9510\n",
      "Epoch 3/10\n",
      "10338/10338 [==============================] - 3s 270us/step - loss: 0.1181 - accuracy: 0.9727\n",
      "Epoch 4/10\n",
      "10338/10338 [==============================] - 2s 242us/step - loss: 0.0833 - accuracy: 0.9790\n",
      "Epoch 5/10\n",
      "10338/10338 [==============================] - 3s 268us/step - loss: 0.0593 - accuracy: 0.9854\n",
      "Epoch 6/10\n",
      "10338/10338 [==============================] - 3s 252us/step - loss: 0.0482 - accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "10338/10338 [==============================] - 3s 266us/step - loss: 0.0417 - accuracy: 0.9908\n",
      "Epoch 8/10\n",
      "10338/10338 [==============================] - 3s 293us/step - loss: 0.0330 - accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "10338/10338 [==============================] - 3s 262us/step - loss: 0.0266 - accuracy: 0.9932\n",
      "Epoch 10/10\n",
      "10338/10338 [==============================] - 3s 264us/step - loss: 0.0253 - accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17d7223b548>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 epochs and batch_size 256 looks the best\n",
    "model.fit(X_train, np.array(y_train), epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score (macro): 0.9872489155064902\n",
      "accuracy_score: 0.9872315728380732\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test)\n",
    "p = [np.argmax(i) for i in p]\n",
    "\n",
    "print(\"f1_score (macro):\", f1_score(y_test, p, average=\"macro\"))\n",
    "print(\"accuracy_score:\", accuracy_score(y_test, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
