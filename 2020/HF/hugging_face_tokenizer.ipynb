{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in d:\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (0.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Peter Norwig's file for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_FILE_URL = 'https://raw.githubusercontent.com/dscape/spell/master/test/resources/big.txt'\n",
    "\n",
    "# Download and save the file\n",
    "from requests import get\n",
    "with open('big.txt', 'wb') as big_f:\n",
    "    response = get(BIG_FILE_URL, )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        big_f.write(response.content)\n",
    "    else:\n",
    "        print(\"Unable to get the file: {}\".format(response.reason))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline and tokenizer.\n",
    "\n",
    "\n",
    "Byte pair encoding or digram coding is a simple form of data compression in which the most common pair of consecutive bytes of data is replaced with a byte that does not occur within that data. A table of the replacements is required to rebuild the original data. The algorithm was first described publicly by Philip Gage in a February 1994 article \"A New Algorithm for Data Compression\" in the C Users Journal.\n",
    "\n",
    "A variant of the technique has shown to be useful in several natural language processing applications.\n",
    "\n",
    "\n",
    "https://leimao.github.io/blog/Byte-Pair-Encoding/\n",
    "\n",
    "https://arxiv.org/abs/2004.03720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.normalizers import Lowercase, NFKC, Sequence\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "\n",
    "# Byte-Pair Encoding model\n",
    "tokenizer = Tokenizer(BPE())\n",
    "\n",
    "# Normalize\n",
    "tokenizer.normalizer = Sequence([\n",
    "    NFKC(),\n",
    "    Lowercase()\n",
    "])\n",
    "\n",
    "# Pre-tokenize\n",
    "tokenizer.pre_tokenizer = ByteLevel()\n",
    "\n",
    "# Plug decoder\n",
    "tokenizer.decoder = ByteLevelDecoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained vocab size: 25000\n"
     ]
    }
   ],
   "source": [
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "trainer = BpeTrainer(vocab_size=25000, show_progress=True, initial_alphabet=ByteLevel.alphabet())\n",
    "tokenizer.train(trainer, [\"big.txt\"])\n",
    "\n",
    "print(\"Trained vocab size: {}\".format(tokenizer.get_vocab_size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\vocab.json', '.\\\\merges.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model.save('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate trained model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Encoded string: ['Ġan', 'Ġant', 'Ġis', 'Ġcraw', 'ling', 'Ġon', 'Ġa', \"\n",
      " \"'Ġpatch', 'Ġof', 'Ġsand', '.', 'Ġas', 'Ġit', 'Ġcraw', 'ls', ',', 'Ġit', \"\n",
      " \"'Ġtraces', 'Ġa', 'Ġline', 'Ġin', 'Ġthe', 'Ġsand', '.', 'Ġby', 'Ġpure', \"\n",
      " \"'Ġchance', 'Ġthe', 'Ġline', 'Ġthat', 'Ġit', 'Ġtraces', 'Ġcurves', 'Ġand', \"\n",
      " \"'Ġrec', 'ross', 'es', 'Ġitself', 'Ġin', ',', 'Ġsuch', 'Ġa', 'Ġway', 'Ġthat', \"\n",
      " \"'Ġit', 'Ġends', 'Ġup', 'Ġlooking', 'Ġlike', 'Ġa', 'Ġrecogn', 'izable', \"\n",
      " \"'Ġcar', 'ic', 'ature', 'Ġof', 'Ġwin', 'ston', 'Ġchurch', 'ill']\")\n",
      "('Decoded string:  an ant is crawling on a patch of sand. as it crawls, it '\n",
      " 'traces a line in the sand. by pure chance the line that it traces curves and '\n",
      " 'recrosses itself in, such a way that it ends up looking like a recognizable '\n",
      " 'caricature of winston churchill')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "tokenizer.model = BPE('vocab.json', 'merges.txt')\n",
    "encoding = tokenizer.encode(\"An ant is crawling on a patch of sand. As it crawls, it traces a line in the sand. By pure chance the line that it traces curves and recrosses itself in, such a way that it ends up looking like a recognizable caricature of Winston Churchill\")\n",
    "\n",
    "pprint(\"Encoded string: {}\".format(encoding.tokens))\n",
    "\n",
    "decoded = tokenizer.decode(encoding.ids)\n",
    "pprint(\"Decoded string: {}\".format(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
